import requests
import json
import os
import time
from datetime import datetime

os.makedirs("output", exist_ok=True)

# Yelp API Configuration
# SECURITY: API keys moved to environment variables
YELP_API_KEY = os.getenv('YELP_API_KEY', '')
YELP_CLIENT_ID = os.getenv('YELP_CLIENT_ID', '')

# API Endpoints
YELP_SEARCH_URL = "https://api.yelp.com/v3/businesses/search"
YELP_BUSINESS_URL = "https://api.yelp.com/v3/businesses"

def extract_allergen_info(text):
    """Extract potential allergen information from menu item text"""
    common_allergens = {
        'dairy': ['milk', 'cheese', 'butter', 'cream', 'yogurt', 'dairy', 'mozzarella', 'cheddar', 'parmesan'],
        'eggs': ['egg', 'eggs', 'mayonnaise', 'mayo'],
        'fish': ['fish', 'salmon', 'tuna', 'cod', 'halibut', 'sea bass', 'mahi'],
        'shellfish': ['shrimp', 'crab', 'lobster', 'oyster', 'mussel', 'clam', 'scallop'],
        'tree_nuts': ['almond', 'walnut', 'pecan', 'cashew', 'pistachio', 'hazelnut', 'pine nut'],
        'peanuts': ['peanut', 'peanuts'],
        'wheat': ['wheat', 'flour', 'bread', 'pasta', 'noodles', 'croutons', 'bun', 'roll'],
        'soy': ['soy', 'tofu', 'edamame', 'miso'],
        'sesame': ['sesame', 'tahini']
    }
    
    detected_allergens = []
    text_lower = text.lower()
    
    for allergen, keywords in common_allergens.items():
        if any(keyword in text_lower for keyword in keywords):
            detected_allergens.append(allergen)
    
    return detected_allergens

def search_chicago_restaurants(limit=50, offset=0):
    """Search for restaurants in Chicago using Yelp API"""
    
    headers = {
        'Authorization': f'Bearer {YELP_API_KEY}',
        'Content-Type': 'application/json'
    }
    
    params = {
        'location': 'Chicago, IL',
        'categories': 'restaurants',
        'limit': limit,  # Max 50 per request
        'offset': offset,
        'sort_by': 'rating',
        'radius': 40000  # 40km radius to cover greater Chicago area
    }
    
    try:
        response = requests.get(YELP_SEARCH_URL, headers=headers, params=params)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"Error searching restaurants: {e}")
        return None

def get_business_details(business_id):
    """Get detailed information about a specific business"""
    
    headers = {
        'Authorization': f'Bearer {YELP_API_KEY}',
        'Content-Type': 'application/json'
    }
    
    try:
        url = f"{YELP_BUSINESS_URL}/{business_id}"
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"Error getting business details for {business_id}: {e}")
        return None

def scrape_all_chicago_restaurants_yelp_api():
    """Comprehensive Chicago restaurant scraper using Yelp API"""
    
    print("üçΩÔ∏è  CHICAGO RESTAURANT SCRAPER - YELP API üçΩÔ∏è")
    print("=" * 50)
    print(f"Using Yelp API Key: {YELP_API_KEY[:20]}...")
    print(f"Target: ALL Chicago restaurants (FREE API tier)\n")
    
    all_restaurants = []
    total_found = 0
    offset = 0
    limit = 50  # Yelp API max per request
    
    # Yelp API allows up to 1000 results total (20 pages of 50)
    max_requests = 20
    
    print("=== FETCHING CHICAGO RESTAURANTS ===")
    
    for page in range(max_requests):
        print(f"\nPage {page + 1}/{max_requests} (offset: {offset})")
        
        # Search for restaurants
        search_results = search_chicago_restaurants(limit=limit, offset=offset)
        
        if not search_results or 'businesses' not in search_results:
            print(f"  ‚ùå No results found for page {page + 1}")
            break
        
        businesses = search_results['businesses']
        total_found = search_results.get('total', 0)
        
        print(f"  üìç Found {len(businesses)} restaurants on this page")
        print(f"  üìä Total available: {total_found} restaurants")
        
        if len(businesses) == 0:
            print(f"  ‚úÖ No more restaurants found, stopping at page {page + 1}")
            break
        
        # Process each restaurant
        for i, business in enumerate(businesses, 1):
            try:
                # Extract basic info
                restaurant_data = {
                    'id': business.get('id', ''),
                    'name': business.get('name', 'Unknown'),
                    'rating': business.get('rating', 0),
                    'review_count': business.get('review_count', 0),
                    'price': business.get('price', 'N/A'),
                    'phone': business.get('phone', ''),
                    'url': business.get('url', ''),
                    'image_url': business.get('image_url', ''),
                    'is_closed': business.get('is_closed', False),
                    'categories': [cat.get('title', '') for cat in business.get('categories', [])],
                    'location': {
                        'address': ' '.join(business.get('location', {}).get('display_address', [])),
                        'city': business.get('location', {}).get('city', ''),
                        'state': business.get('location', {}).get('state', ''),
                        'zip_code': business.get('location', {}).get('zip_code', ''),
                        'coordinates': {
                            'latitude': business.get('coordinates', {}).get('latitude', 0),
                            'longitude': business.get('coordinates', {}).get('longitude', 0)
                        }
                    },
                    'transactions': business.get('transactions', []),
                    'source': 'Yelp API',
                    'scraped_at': datetime.now().isoformat()
                }
                
                # Get detailed business information
                business_id = business.get('id')
                if business_id:
                    print(f"    {i:2d}. {restaurant_data['name']} (Rating: {restaurant_data['rating']})")
                    
                    # Get additional details
                    details = get_business_details(business_id)
                    if details:
                        restaurant_data.update({
                            'hours': details.get('hours', []),
                            'special_hours': details.get('special_hours', []),
                            'photos': details.get('photos', []),
                            'messaging': details.get('messaging', {})
                        })
                    
                    # Analyze categories for allergen-friendly info
                    categories_text = ' '.join(restaurant_data['categories']).lower()
                    dietary_info = {
                        'vegetarian_friendly': any(term in categories_text for term in ['vegetarian', 'vegan', 'salad', 'juice']),
                        'gluten_free_options': any(term in categories_text for term in ['gluten', 'health', 'organic']),
                        'allergy_conscious': any(term in categories_text for term in ['organic', 'health', 'fresh', 'natural'])
                    }
                    restaurant_data['dietary_analysis'] = dietary_info
                    
                    all_restaurants.append(restaurant_data)
                    
                    # Brief pause to respect API rate limits
                    time.sleep(0.1)
                
            except Exception as e:
                print(f"    ‚ùå Error processing restaurant {i}: {e}")
                continue
        
        offset += limit
        
        # Brief pause between pages
        time.sleep(1)
        
        # Check if we've reached the end
        if len(businesses) < limit:
            print(f"  ‚úÖ Reached end of results at page {page + 1}")
            break
    
    # Calculate statistics
    unique_restaurants = all_restaurants  # Yelp API returns unique results
    
    # Analyze data
    rating_distribution = {}
    price_distribution = {}
    category_counts = {}
    
    for restaurant in unique_restaurants:
        # Rating distribution
        rating = restaurant.get('rating', 0)
        rating_key = f"{int(rating)}.0-{int(rating)}.9"
        rating_distribution[rating_key] = rating_distribution.get(rating_key, 0) + 1
        
        # Price distribution
        price = restaurant.get('price', 'N/A')
        price_distribution[price] = price_distribution.get(price, 0) + 1
        
        # Category analysis
        for category in restaurant.get('categories', []):
            category_counts[category] = category_counts.get(category, 0) + 1
    
    # Create final dataset
    final_data = {
        'scraping_summary': {
            'date': datetime.now().isoformat(),
            'city': 'Chicago, Illinois',
            'total_restaurants': len(unique_restaurants),
            'api_source': 'Yelp Fusion API',
            'api_cost': '$0 (FREE tier)',
            'api_calls_used': len(unique_restaurants) + (offset // limit),
            'daily_limit_remaining': 5000 - (len(unique_restaurants) + (offset // limit)),
            'coverage_estimate': f"{min(100, (len(unique_restaurants) / 8000) * 100):.1f}% of Chicago restaurants",
            'data_quality': 'High (verified business data)',
            'rating_distribution': rating_distribution,
            'price_distribution': price_distribution,
            'top_categories': dict(sorted(category_counts.items(), key=lambda x: x[1], reverse=True)[:10])
        },
        'restaurants': unique_restaurants
    }
    
    # Save results
    output_file = "output/chicago_restaurants_yelp_api.json"
    with open(output_file, 'w') as f:
        json.dump(final_data, f, indent=2)
    
    # Print comprehensive summary
    print(f"\n" + "=" * 60)
    print(f"üéâ CHICAGO RESTAURANT COLLECTION COMPLETE! üéâ")
    print(f"=" * 60)
    print(f"üìä Total restaurants collected: {len(unique_restaurants)}")
    print(f"üí∞ API cost: $0 (FREE Yelp API tier)")
    print(f"üìû API calls used: {len(unique_restaurants) + (offset // limit)}")
    print(f"üîÑ Daily limit remaining: {5000 - (len(unique_restaurants) + (offset // limit))}")
    print(f"üìÅ Results saved to: {output_file}")
    
    print(f"\nüìà RATING DISTRIBUTION:")
    for rating_range, count in sorted(rating_distribution.items()):
        print(f"  ‚≠ê {rating_range}: {count} restaurants")
    
    print(f"\nüíµ PRICE DISTRIBUTION:")
    for price, count in sorted(price_distribution.items()):
        price_desc = {
            '$': 'Budget-friendly',
            '$$': 'Moderate',
            '$$$': 'Expensive',
            '$$$$': 'Very Expensive',
            'N/A': 'Price not listed'
        }.get(price, price)
        print(f"  üí≤ {price} ({price_desc}): {count} restaurants")
    
    print(f"\nüçΩÔ∏è TOP RESTAURANT CATEGORIES:")
    for category, count in list(sorted(category_counts.items(), key=lambda x: x[1], reverse=True))[:10]:
        print(f"  üè∑Ô∏è {category}: {count} restaurants")
    
    print(f"\nüè• HEALTH APP INTEGRATION:")
    vegetarian_count = sum(1 for r in unique_restaurants if r.get('dietary_analysis', {}).get('vegetarian_friendly', False))
    allergy_conscious_count = sum(1 for r in unique_restaurants if r.get('dietary_analysis', {}).get('allergy_conscious', False))
    
    print(f"  ü•ó Vegetarian-friendly: {vegetarian_count} restaurants")
    print(f"  üè• Allergy-conscious: {allergy_conscious_count} restaurants")
    print(f"  üìç All restaurants have precise coordinates for mapping")
    print(f"  ‚≠ê All restaurants have verified ratings and reviews")
    
    print(f"\nüöÄ SCALING TO MORE RESTAURANTS:")
    print(f"  üìä Current collection: {len(unique_restaurants)} restaurants")
    print(f"  üéØ Yelp API limit: 1,000 restaurants per search")
    print(f"  üîÑ Daily API calls: 5,000 (FREE tier)")
    print(f"  üí° To get more: Use multiple search terms, neighborhoods, or categories")
    print(f"  üí∞ Cost for 10,000+ restaurants: Still $0 with smart API usage!")
    
    print(f"\n‚úÖ PERFECT FOR YOUR ALLERGY APP:")
    print(f"  üè• Comprehensive restaurant database")
    print(f"  üìç Precise location data for all restaurants")
    print(f"  ‚≠ê Verified ratings and review counts")
    print(f"  üè∑Ô∏è Detailed category information")
    print(f"  üí∞ Zero cost with FREE Yelp API")
    print(f"  üîÑ Easy to update and maintain")
    
    # Show sample restaurants
    print(f"\nüçΩÔ∏è SAMPLE CHICAGO RESTAURANTS:")
    for i, restaurant in enumerate(unique_restaurants[:8], 1):
        categories = ', '.join(restaurant.get('categories', [])[:2])
        rating = restaurant.get('rating', 0)
        price = restaurant.get('price', 'N/A')
        address = restaurant.get('location', {}).get('address', 'Address not available')
        print(f"  {i}. {restaurant['name']}")
        print(f"     üìç {address}")
        print(f"     ‚≠ê {rating}/5 ({restaurant.get('review_count', 0)} reviews)")
        print(f"     üí≤ {price} | üè∑Ô∏è {categories}")
        print()
    
    return final_data

if __name__ == "__main__":
    print("üöÄ Starting Chicago Restaurant Collection with Yelp API...\n")
    
    # Test API connection first
    print("üîç Testing Yelp API connection...")
    test_result = search_chicago_restaurants(limit=1)
    
    if test_result and 'businesses' in test_result:
        print(f"‚úÖ API connection successful!")
        print(f"üìä Total restaurants available: {test_result.get('total', 'Unknown')}")
        print(f"üí∞ Using FREE Yelp API tier\n")
        
        # Run the full scraper
        results = scrape_all_chicago_restaurants_yelp_api()
        
        print(f"\nüéä SUCCESS! You now have a comprehensive Chicago restaurant database!")
        print(f"üí° This demonstrates how to collect thousands of restaurants for FREE!")
        print(f"üè• Perfect foundation for your health-based allergy app!")
        
    else:
        print(f"‚ùå API connection failed. Please check your API key.")
        print(f"üîë Current API Key: {YELP_API_KEY[:20]}...")
        print(f"üí° Make sure your Yelp API key is valid and active.")